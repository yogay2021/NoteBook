## 经典的深层卷积神经网络

LeNet 5

![image-20230116135253360](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116135253360.png)

> 主要的框架是多组【卷积层加上池化层】的组合，最后全连接层

## 残差网络

输入的数据直接连接到深层网络。

![image-20230116143926071](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116143926071.png)

下面式子是深度网络中加入输入的表达

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116152902397.png" alt="image-20230116152902397" style="zoom:33%;" />

ResNet网络是多个残差网络构成的：5个残差块连接在一起

![image-20230116171309786](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116171309786.png)

一般上判断随着网络层数越来越深，训练效果会越来越好，但是在普遍网络不是这样的，error在下降到某一最低点后就会上升。

ResNet网络则符合判断，网络层数越来越深，训练效果会越来越好。

![image-20230116171606893](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116171606893.png)

总结而言，引入残差块能够有效的提升深层网络的效果。

## 网络中的网络

>具体含义是指用 1 * 1 * k  的卷积核进行运算

如果网络是单层的，那么这样的卷积运算只有放大效用。

 若网络层数本身较大，这会起到如压缩这样的效果。

![image-20230116202439066](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116202439066.png)

如果采用了多个卷积核，那么输出的层数也是这个数量。

![image-20230116202654132](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116202654132.png)

## Inception网络

对前序网络的处理有很多种选择，不同大小的卷积核，以及池化层的选择。把各种选择的输出结果以原大小叠加在一起。

![image-20230116204510985](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116204510985.png)

下列是一个inception模块：

![image-20230116204833333](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116204833333.png)

完整的inception net 就是以多个模块组成。

![image-20230116205340081](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116205340081.png)



## 迁移学习

**只有较小的数据集时：**

> downloa的神经网络以及权重，冻结前部分的神经网络，只是对softmax部分的权重进行训练

![image-20230116211622090](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116211622090.png)



**具有较大的数据集时：**

> 考虑冻结较少部分的网络，对于其余部分：或是再训练一部分的网络，或是替换一部分网络。

![image-20230116212032155](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116212032155.png)



**具有十分庞大的数据集时：**

> 这种情况则所有的网络权重都从头训练，设置对应的softmax层

---

## 数据扩充

 **镜像反转**

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116212915171.png" alt="image-20230116212915171" style="zoom:33%;" />

**随机剪裁：**

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116212958873.png" alt="image-20230116212958873" style="zoom:33%;" />

**色彩转换：**

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230116213204968.png" alt="image-20230116213204968" style="zoom:33%;" />

> 考虑了不同场景下的对象色彩差异，模型会更具有鲁棒性。