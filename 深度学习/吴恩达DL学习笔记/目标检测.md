

## 对于任务类型的区分

> 分类问题只需要判断图像是不是对应的类别。
>
> 目标检测需要更进一步，不仅需要判断是否是对应的类别，还需要检测目标的位置，进行标注。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230118113006391.png" alt="image-20230118113006391" style="zoom:50%;" />

## 标注框的数据格式

作为数据集的标注框，表示形式包含6个数字：

> pc表示出现的对象数；c则表示对象的种类编号（如此处设置的车编号是3）

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230117212103278.png" alt="image-20230117212103278" style="zoom:67%;" />



## 锚框Anchor box

锚框与物体边界框不同，是假想出来的一种框。预先设定好锚框的大小和形状，再以图像上某一个点为中心画出矩形框。

> 在目标检测任务中，通常会以某种规则在图片上生成一系列锚框:
>
> 将这些锚框当成可能的候选区域。模型对这些候选区域是否包含物体进行预测，如果包含目标物体，则还需要进一步预测出物体所属的类别。
>
> 由于锚框位置是固定的，它不大可能刚好跟物体边界框重合，所以需要在锚框的基础上进行微调以形成能准确描述物体位置的预测框，模型需要预测出微调的幅度。
>
> 在训练过程中，模型通过学习不断的调整参数，最终能学会如何判别出锚框所代表的候选区域是否包含物体，如果包含物体的话，物体属于哪个类别，以及物体边界框相对于锚框位置需要调整的幅度。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230118134908090.png" alt="image-20230118134908090" style="zoom:33%;" />

## 交并比

> 使用交并比（Intersection of Union，IoU）作为衡量指标来衡量锚框跟真实框之间的关系。

具体的计算如下：

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230118135316368.png" alt="image-20230118135316368" style="zoom:50%;" />

可视化理解：

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230118135409559.png" alt="image-20230118135409559" style="zoom:50%;" />



