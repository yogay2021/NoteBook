## 神经网络简单理解

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113201852592.png" alt="image-20230113201852592" style="zoom:50%;" />

神经网络可以理解为一个由多维度的输入到输出结果的映射，通过数据集的训练以及测试集的修正能够使得这个映射达到相当理想的效果。例如输入可能与房价相关的因素（地理位置，面积，采光情况等），输出是房价。通过将这些因素量化作为数据集，我们可以得到一个某种意义上比较可观的房价计算器，这个计算器也是一个神经网络。

---



## 神经网络应用

图像方向-多用CNN卷积

带有序列数据性质的（音频，语言） - 多用RNN循环神经网络

结构化数据：表示清晰的数据如房价，年龄

非结构化数据： 意义丰富的数据，如图像，音频

---



## 二分类

==**图像输入的形式：**==

RGB三个通道亮度对应三个矩阵，将所有元素取出放入【1 * nx】的特征向量内输入。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113205431641.png" alt="image-20230113205431641" style="zoom:50%;" />

对于数据集，包含（输入的特征向量，输出结果）两个部分，（如输入图像判定识别结果）。m组数据集第一部分表示为【nx * m】的矩阵，第二部分表示为【1 * m】的矩阵，

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113205920384.png" alt="image-20230113205920384" style="zoom:33%;" />

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113205935024.png" alt="image-20230113205935024" style="zoom:33%;" />



==**逻辑回归：**==

预期的结果表示为线性形式，在外层套上一个sigmoid函数，使得结果映射在0到1之间，用以表示趋向于某一结果的概率。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113215225857.png" alt="image-20230113215225857" style="zoom:50%;" />

sigmoid函数：

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113215305207.png" alt="image-20230113215305207" style="zoom:33%;" />

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113215318055.png" alt="image-20230113215318055" style="zoom:33%;" />



适用于逻辑回归的loss函数：

期望是输出的结果与实际结果尽可能的接近，也就表征了神经网络的回归效果很好，通过loss函数能够表现这个差异程度，当然也需要根据具体问题来选择loss函数，如差平方loss不适合逻辑回归，可能导致多个局部较优==（此处这个结论不了解是如何取得的，或许需要一些数学方法，暂时保留疑问）==。

下面是采用的loss函数：

![image-20230113215827591](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113215827591.png)



==**梯度下降法：**==

通过loss我们能够获得一个表征输出结果准确程度的指标，凭借这个指标使用梯度下降法能够取得使得神经网络回归效果最好的这个[w,b]。

首先从一个参数的情况来进行理解：

学习率是每一次迭代中w修正的距离，通过求导，w能够以最快的速度下降到使得loss最小的点。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113221407491.png" alt="image-20230113221407491" style="zoom:50%;" />

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113221337911.png" alt="image-20230113221337911" style="zoom:33%;" />

在维度更高的情况下也是类似的：

各个方向（也就是参数）上的loss求导，以最快的速度向使得loss最低的点逼近，多轮迭代可以获得期望的[w,b]。

当然，还需要控制学习率或是步长，过大会一直越过最低点，过小需要很庞大的迭代次数。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113221714041.png" alt="image-20230113221714041" style="zoom:33%;" />

---



## 计算流程图

把神经网络中的计算进行拆解，以流程的形式表示：

如下面的计算式子：

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230114102059754.png" alt="image-20230114102059754" style="zoom:50%;" />

可以拆解为：

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230114102122231.png" alt="image-20230114102122231" style="zoom:50%;" />

流程图就表示为：

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230114102147658.png" alt="image-20230114102147658" style="zoom:50%;" />

具体应用能够直观的表现输入数据的处理流程，当然还会用于导数的传递计算。

---



## 向量化

从向量的角度来计算，速度会快于使用列表数组的形式。网络层次扩大之后，为确保快速性，向量化是必要的。实际的时间差可能到达上百倍，应当避免for循环的出现。

例如在逻辑回归问题中，需要按照数据集列出多组表达式：

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230114160236916.png" alt="image-20230114160236916" style="zoom:50%;" />

向量化之后只需要一行代码就能完成这个任务：

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230114160348959.png" alt="image-20230114160348959" style="zoom:50%;" />

```python
Z = np.dot(w,x) + b
```

---



## np的广播机制

在向量计算中自动补齐形状不一致的矩阵，例如：

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230114162758838.png" alt="image-20230114162758838" style="zoom:50%;" />

将实数补齐成[1 * 4]的向量，然后正常进行运算。

---



## numpy中避免BUG的写法

```python
a = np.random.randn(5)
## 输出a.shape = (5,) ,这只是秩为1的矩阵，可能存在广播,以后的运算也可能有问题

a = np.random.randn(5,1)
## 这样定义明确输出的a.shape = (5,1) ,合理。
```
