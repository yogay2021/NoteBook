# 日志



## 早上

观看去年的完全模型线上赛培训视频，了解到了一些打榜技巧以及模型优化的方法，记录笔记。

## 下午

1.翻阅了一些edgeboard的部署资料。

2.学习opencv图像处理操作，在notebook逐个实践。

## 晚上

1.总结opencv学习笔记

2.在leecode上做了若干数据结构编程题

# 学习记录

## 从数据层面优化

> 预计第一阶段线上资格赛的评判标准主要应该是对于模型优化程度的比较

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230131164453055.png" alt="image-20230131164453055" style="zoom:50%;" />

### 数据集均衡化

> 例如数据集的大部分目标位置都是位于中间的位置。
>
> 可以通过适当的截取以及分割，保留图像的目标核心，使得模型学习更加专注，并且在一定程度上改变位置。



### 数据增强

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230131215036850-1675260869119-29.png" alt="image-20230131215036850" style="zoom: 50%;" />

> 数据增强对于模型训练会是一个较为有效的手段
>
> 需要关注的是，根据具体任务来选择数据增强的手段

==**对于有想法的数据增强手段,通过实验性的训练模型（简单的跑若干个epoch即可）来观察是最好的验证手段**==

> paddleseg 的 Rich Crop 数据增强策略可以考虑使用



## 从训练角度优化

### 模型选择

根据 推理时间图 以及 参数量图 来选择<高交并比，短推理速度>的模型

并不是所有的模型都需要尝试，有限度的选择较优的。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230201093743503-1675260869119-31.png" alt="image-20230201093743503" style="zoom:33%;" />

> 有时间可以考虑阅读模型的论文，深入理解其优化思想

### 模型优化的思路

1.深度层面

2.多宽度多尺度

3.残差连接，更快的的收敛

### 超参数优化

1.考虑优化器的种类

2.学习率的调整

3.数据增强方法的选择

> 在实验总部需要关注控制变量，并且做好记录

### 损失函数

> 考虑在基准的损失函数上添加一些辅助的损失函数
>
> 效果需要测试，不一定有效

## 从模型角度优化

> 数据集中可能存在一些被污染或者是有标注错误的数据集，这里给出了一个测试手段：
>
> 正常的训练模型，在测试阶段，令batchsize为  1 ，一张一张的输入， 然后得到一组评价指标 ，明显离群的数据（加个遍历判据）可以取出单独分析。
>
> 标注错误就手动校正，模型学习有问题再具体分析优化

![image-20230201110022276](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230201110022276.png)

### 测试时增强

> 在推理时，给模型展示多个经过随机变化的图像，结果取其平均
>
> 时间换精度，根据任务考虑，不一定有效
>
> 项目地址：
>
> https://girhub.com/AgentMaker/PaTTA

![image-20230201112016362](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230201112016362.png)



## 打榜技巧

### 量化实现性能优化

> 读取图像时，把数据的精度降低，可以获得更快的推理速度

![image-20230201134029858](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230201134029858-1675260869119-37.png)

> 此处是在推理时的使用，训练依然使用正常的数据精度



> 下面是模型性能的三种优化手段：
>
> 量化是减小数据的空间从而减少计算量
>
> 模型剪枝以及蒸馏较为复杂，后面找机会详细学习

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230201134354146.png" alt="image-20230201134354146" style="zoom:150%;" />

### 综合优化建议

> 先考虑前序的数据优化策略，最后再尝试模型优化

![image-20230201135026113](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230201135026113.png)







## 颜色空间转换

```python
#BGR2GRAY
cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
#BGR2HSV
cv2.cvtColor(image,cv2.COLOR_BGR2HSV)
```

> HSV格式中：
>
> H（色彩/色度）的取值范围是 [0，179]，
>
> S（饱和度）的取值范围 [0，255]，
>
> V（亮度）的取值范围 [0，255]

## 拓展缩放

```python
cv2.resize(src, dsize, dst=None, fx=None, fy=None, interpolation=None)
#cv2.resize(原图，输出尺寸，输出图，水平比例，垂直比例，插值方法)
```

下面是实例：

```python
dst = cv2.resize(img,(500,500))	
```

## 平移

```python
w,h,n = img.shape
M = np.float32([[1,0,Tx],[0,1,Ty]]) #使用numpy构建移动矩阵
res = cv2.warpAffine(img,M,(w,h)) 
#第一个参数为原图，第二个参数为移动矩阵，第三个参数为输出图像大小
```

移动矩阵M实际是一个拼接的矩阵，左侧的 2 * 2 是与原图位置信息的相乘矩阵，右侧的Tx，Ty是与原图位置信息的作和矩阵（在乘积之后）。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230127201829111-1675241542602-1-1675260645095-9.png" alt="image-20230127201829111" style="zoom: 67%;" />

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230127201923409-1675241542603-3-1675260645095-11.png" alt="image-20230127201923409" style="zoom:50%;" />

## 旋转

> 用getRotationMatrix2D构建一个表征旋转参数的矩阵以及使用warpAffine进行映射。

```python
#第一个参数旋转中心，第二个参数旋转角度，第三个参数：缩放比例 
M = cv2.getRotationMatrix2D((cols/2,rows/2),45,1) 
#第三个参数：变换后的图像大小 
res = cv2.warpAffine(img,M,(rows,cols))
```

## 图像阈值

==简单阈值==

```python
cv2.threshold(src, thresh, maxval, type)
#原图，阈值，最大值，划分类型
```

> 阈值的划分类型有以下：
>
> ![这里写图片描述](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/70-1675260645095-13.png)

下图是运行结果：

```python
import cv2
import numpy as np
from matplotlib import pyplot as plt

img = cv2.imread("E:/DeskTop/photo/dog1.jpg",0)
ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)
ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)
ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)
ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)
ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)

titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']
images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]

for i in range(6):
    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')
    plt.title(titles[i])
    plt.xticks([]),plt.yticks([])

plt.show()
```

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230201202841328-1675260645095-17.png" alt="image-20230201202841328" style="zoom:67%;" />

==自适应阈值==

> 对于自适应性阈值的理解：
>
> 如果图像灰度的分布情况非常不均匀，例如一边偏白一边偏黑，全局的阈值分割会导致很割裂的结果（上面的例子就是直接在图中央有分割线）。
>
> 自适应阈值是图中的每个像素周围围出一个N * N的范围，计算这个范围里的灰度阈值。

```python
cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C, dst=None)
#原图，最大值，自适应阈值算法，二值化方法，分割的区块边长N，常数C，
```

> 常数C：各个邻域计算出阈值后再减去C作为最终阈值
>
> adaptiveMethod 自适应阈值分割算法如下：
>
> ADAPTIVE_THRESH_MEAN_C : 计算区域块的平均值
>
> ADAPTIVE_THRESH_GAUSSIAN_C : 按照距离进行加权计算

**实践：**

```python
import cv2
import numpy as np
from matplotlib import pyplot as plt

img = cv2.imread("E:/DeskTop/photo/dog1.jpg",0)
img = cv2.medianBlur(img,5)

ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)
th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\
            cv2.THRESH_BINARY,11,2)
th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY,11,2)

titles = ['Original Image', 'Global Thresholding ',
            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']
images = [img, th1, th2, th3]

for i in range(4):
    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')
    plt.title(titles[i])
    plt.xticks([]),plt.yticks([])
plt.show()
```

![image-20230201213855335](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230201213855335-1675260645095-15.png)

==OTSU二值化==

> 自动选取较优的阈值

```python
ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)
```

在简单阈值的基础上，依然使用threshold，需要+cv2.THRESH_OTSU

返回值包含两个部分，最优阈值以及分割结果。

> 而且此方法对于噪声较为敏感，滤波之后再使用更好。

实践：

```python
import cv2
import numpy as np
from matplotlib import pyplot as plt

img = cv2.imread("E:/DeskTop/photo/dog1.jpg",0)

blur = cv2.GaussianBlur(img,(5,5),0)
ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)
print(ret3)
plt.subplot(121),plt.imshow(img),plt.title('Input')
plt.subplot(122),plt.imshow(th3),plt.title('Output')
plt.show()
```

![image-20230201220545212](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230201220545212-1675260645096-19.png)



