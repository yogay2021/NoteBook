# 学习总结

## 神经网络简单理解

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113201852592-1673619833621-1.png" alt="image-20230113201852592" style="zoom:50%;" />

神经网络可以理解为一个由多维度的输入到输出结果的映射，通过数据集的训练以及测试集的修正能够使得这个映射达到相当理想的效果。例如输入可能与房价相关的因素（地理位置，面积，采光情况等），输出是房价。通过将这些因素量化作为数据集，我们可以得到一个某种意义上比较可观的房价计算器，这个计算器也是一个神经网络。

---



## 神经网络应用

图像方向-多用CNN卷积

带有序列数据性质的（音频，语言） - 多用RNN循环神经网络

结构化数据：表示清晰的数据如房价，年龄

非结构化数据： 意义丰富的数据，如图像，音频

---



## 二分类问题

==**图像输入的形式：**==

RGB三个通道亮度对应三个矩阵，将所有元素取出放入【1 * nx】的特征向量内输入。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113205431641-1673619833621-3.png" alt="image-20230113205431641" style="zoom:50%;" />

对于数据集，包含（输入的特征向量，输出结果）两个部分，（如输入图像判定识别结果）。m组数据集第一部分表示为【nx * m】的矩阵，第二部分表示为【1 * m】的矩阵，

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113205920384-1673619833621-5.png" alt="image-20230113205920384" style="zoom:33%;" />

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113205935024-1673619833621-7.png" alt="image-20230113205935024" style="zoom:33%;" />



==**逻辑回归：**==

预期的结果表示为线性形式，在外层套上一个sigmoid函数，使得结果映射在0到1之间，用以表示趋向于某一结果的概率。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113215225857-1673619833621-9.png" alt="image-20230113215225857" style="zoom:50%;" />

sigmoid函数：

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113215305207-1673619833622-11.png" alt="image-20230113215305207" style="zoom:33%;" />

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113215318055-1673619833622-13.png" alt="image-20230113215318055" style="zoom:33%;" />



适用于逻辑回归的loss函数：

期望是输出的结果与实际结果尽可能的接近，也就表征了神经网络的回归效果很好，通过loss函数能够表现这个差异程度，当然也需要根据具体问题来选择loss函数，如差平方loss不适合逻辑回归，可能导致多个局部较优==（此处这个结论不了解是如何取得的，或许需要一些数学方法，暂时保留疑问）==。

下面是采用的loss函数：

![image-20230113215827591](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113215827591-1673619833622-15.png)



==**梯度下降法：**==

通过loss我们能够获得一个表征输出结果准确程度的指标，凭借这个指标使用梯度下降法能够取得使得神经网络回归效果最好的这个[w,b]。

首先从一个参数的情况来进行理解：

学习率是每一次迭代中w修正的距离，通过求导，w能够以最快的速度下降到使得loss最小的点。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113221407491-1673619833622-17.png" alt="image-20230113221407491" style="zoom:50%;" />

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113221337911-1673619833622-19.png" alt="image-20230113221337911" style="zoom:33%;" />

在维度更高的情况下也是类似的：

各个方向（也就是参数）上的loss求导，以最快的速度向使得loss最低的点逼近，多轮迭代可以获得期望的[w,b]。

当然，还需要控制学习率或是步长，过大会一直越过最低点，过小需要很庞大的迭代次数。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230113221714041-1673619833622-21.png" alt="image-20230113221714041" style="zoom:33%;" />

# 进度总结

由于之前也接触过深度学习，有一些经验，吴恩达的DL课程学习目前没有遇到很大的困难，前序的基础内容我基本都有了解，所以暂时新的收获不多，就当做复习。估计DL课程的学习进度预计会比预期提前完成。

# 检讨书

今天是上班第二天，本人就不慎迟到打卡，确实是极其不应该的错误。问题还是在于个人没有关注好时间，虽然已经起床，但是没有及时的打卡，吃早餐也没有注意时间，吃完早餐才发现已经过了八点。我了解车队对于纪律的重视，对于此次迟到的处罚我心服口服的接受也进行的全面的反思。曾子云；吾日三省吾身，我希望这次迟到之后我给自己再加上“一省”：有时间观念，珍惜时间否？经过反省，我一定严格要求自己，此后一定服从纪律安排，按时上班签到，早起学习，充实自己，珍惜时间。





