# 学习总结

## 标注框的数据格式

作为数据集的标注框，表示形式包含6个数字：

> pc表示出现的对象数；c则表示对象的种类编号（如此处设置的车编号是3）

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230117212103278.png" alt="image-20230117212103278" style="zoom:67%;" />



## 锚框Anchor box

锚框与物体边界框不同，是假想出来的一种框。预先设定好锚框的大小和形状，再以图像上某一个点为中心画出矩形框。

> 在目标检测任务中，通常会以某种规则在图片上生成一系列锚框:
>
> 将这些锚框当成可能的候选区域。模型对这些候选区域是否包含物体进行预测，如果包含目标物体，则还需要进一步预测出物体所属的类别。
>
> 由于锚框位置是固定的，它不大可能刚好跟物体边界框重合，所以需要在锚框的基础上进行微调以形成能准确描述物体位置的预测框，模型需要预测出微调的幅度。
>
> 在训练过程中，模型通过学习不断的调整参数，最终能学会如何判别出锚框所代表的候选区域是否包含物体，如果包含物体的话，物体属于哪个类别，以及物体边界框相对于锚框位置需要调整的幅度。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230118134908090.png" alt="image-20230118134908090" style="zoom:33%;" />

## 交并比

> 使用交并比（Intersection of Union，IoU）作为衡量指标来衡量锚框跟真实框之间的关系。

具体的计算如下：

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230118135316368-1674055316942-5.png" alt="image-20230118135316368" style="zoom:50%;" />

可视化理解：

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230118135409559-1674055316942-7.png" alt="image-20230118135409559" style="zoom:50%;" />



## 框架选择

为了更快适应后续比赛使用的paddle平台，我选择直接使用paddlepaddle来搭建网络框架。

## LeNet原论文的网络结构复现

> 基于paddle的网络结构搭建能明显感觉到代码工作量的减小，例如卷积层的引入，实际运算还需要进行向量化等运算操作，前面进行浅层神经网络的搭建时也已经体验过了。这里把大量的运算操作都集成在paddle包中，只需要调用对应的API就可以进行预期的卷积计算了。

**代码块：**

```python
import paddle.nn as nn

network = nn.Sequential(
    nn.Conv2D(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),  
    # C1 卷积层
    nn.Tanh(),
    nn.AvgPool2D(kernel_size=2, stride=2),  # S2 平局池化层
    nn.Sigmoid(),   # Sigmoid激活函数
    nn.Conv2D(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0), 
    # C3 卷积层
    nn.Tanh(),
    nn.AvgPool2D(kernel_size=2, stride=2),  # S4 平均池化层
    nn.Sigmoid(),  # Sigmoid激活函数
    nn.Conv2D(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=0), 
    # C5 卷积层
    nn.Tanh(),
    nn.Flatten(),
    nn.Linear(in_features=120, out_features=84), # F6 全连接层
    nn.Tanh(),
    nn.Linear(in_features=84, out_features=10) # OUTPUT 全连接层
)
```

对于代码的理解涉及到许多API的使用，下面进行J简单的总结：

==paddle.nn:==

第三行的`nn.Sequential`，是一个顺序容器。子 Layer 将按构造函数参数的顺序添加到此容器中。简单来说就是封装网络结构的一个容器。

==nn.Conv2D：==

指代的是二维卷积层（convolution2d layer），根据输入、卷积核、步长（stride）、填充（padding）、空洞大小（dilations）一组参数计算输出特征层大小。具体的参数含义如下：

- **in_channels** (int) - 输入图像的通道数。
- **out_channels** (int) - 由卷积操作产生的输出的通道数。
- **kernel_size** (int) - 卷积核大小。可以为单个整数或包含两个整数的元组或列表，分别表示卷积核的高和宽。如果为单个整数，表示卷积核的高和宽都等于该整数。
- **stride** (int|list|tuple，可选) - 步长大小。可以为单个整数或包含两个整数的元组或列表，分别表示卷积沿着高和宽的步长。如果为单个整数，表示沿着高和宽的步长都等于该整数。默认值：1。
- **padding** (int|list|tuple|str，可选) - 填充大小。

> 完整包含了卷积的参数，在构建卷积核的流程被极大的简化了，确实是很方便的工具

==nn.Sigmoid()==

创建一个 `Sigmoid` 的可调用类。这个类可以计算输入 x 经过激活函数 sigmoid 之后的值。

 # 进度总结

吴恩达的深度学习的课程学习任务今天就全部完成了，早上把不太理解的地方再看了一下，然后总结好了所有的课程笔记，压缩好提交了作业。然后下午进行下一部分的任务，原来是预定的学习数据增强方法，但是考虑刚刚学习完卷积网络，通过手写数字识别的项目能够更好的深化理解，所以先进行手写数字识别的任务。由于使用的是paddle框架，这个框架以前没有接触过，下午花了很多时间去熟悉。晚上初步模仿LENET初步搭建了神经网络的主体，认识了paddle框架卷积池化以及一些激活函数的API含义。明天预计完成手写数字识别的任务。

![image-20230118233201226](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230118233201226.png)









