# 学习总结



## 框架选择

为了更快适应后续比赛使用的paddle平台，我选择直接使用paddlepaddle来搭建网络框架。

完整的项目已经上传到paddle的线上平台，地址如下：

[手写数字识别 - 飞桨AI Studio (baidu.com)](https://aistudio.baidu.com/aistudio/projectdetail/5406880?contributionType=1)

## LeNet原论文的网络结构复现

> 基于paddle的网络结构搭建能明显感觉到代码工作量的减小，例如卷积层的引入，实际运算还需要进行向量化等运算操作，前面进行浅层神经网络的搭建时也已经体验过了。这里把大量的运算操作都集成在paddle包中，只需要调用对应的API就可以进行预期的卷积计算了。

### 网络主体搭建

**代码块：**

```python
import paddle.nn as nn

network = nn.Sequential(
    nn.Conv2D(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),  
    # C1 卷积层
    nn.Tanh(),
    nn.AvgPool2D(kernel_size=2, stride=2),  # S2 平局池化层
    nn.Sigmoid(),   # Sigmoid激活函数
    nn.Conv2D(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0), 
    # C3 卷积层
    nn.Tanh(),
    nn.AvgPool2D(kernel_size=2, stride=2),  # S4 平均池化层
    nn.Sigmoid(),  # Sigmoid激活函数
    nn.Conv2D(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=0), 
    # C5 卷积层
    nn.Tanh(),
    nn.Flatten(),
    nn.Linear(in_features=120, out_features=84), # F6 全连接层
    nn.Tanh(),
    nn.Linear(in_features=84, out_features=10) # OUTPUT 全连接层
)
```

### API笔记

对于代码的理解涉及到许多API的使用，下面进行J简单的总结：

==paddle.nn:==

第三行的`nn.Sequential`，是一个顺序容器。子 Layer 将按构造函数参数的顺序添加到此容器中。简单来说就是封装网络结构的一个容器。

==nn.Conv2D：==

指代的是二维卷积层（convolution2d layer），根据输入、卷积核、步长（stride）、填充（padding）、空洞大小（dilations）一组参数计算输出特征层大小。具体的参数含义如下：

- **in_channels** (int) - 输入图像的通道数。
- **out_channels** (int) - 由卷积操作产生的输出的通道数。
- **kernel_size** (int) - 卷积核大小。可以为单个整数或包含两个整数的元组或列表，分别表示卷积核的高和宽。如果为单个整数，表示卷积核的高和宽都等于该整数。
- **stride** (int|list|tuple，可选) - 步长大小。可以为单个整数或包含两个整数的元组或列表，分别表示卷积沿着高和宽的步长。如果为单个整数，表示沿着高和宽的步长都等于该整数。默认值：1。
- **padding** (int|list|tuple|str，可选) - 填充大小。

> 完整包含了卷积的参数，在构建卷积核的流程被极大的简化了，确实是很方便的工具

==nn.Sigmoid()==

创建一个 `Sigmoid` 的可调用类。这个类可以计算输入 x 经过激活函数 sigmoid 之后的值。

![image-20230118231917855](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230118231917855-1674135943448-1.png)



==nn.AvgPool2D()==

构建 AvgPool2D 类的一个可调用对象，其将构建一个二维平均池化层，根据输入参数 kernel_size, stride, padding 等参数对输入做平均池化操作。

一些具体的参数设置如下：

- **kernel_size** (int|list|tuple)：池化核大小。如果它是一个元组或列表，它必须包含两个整数值，(pool_size_Height, pool_size_Width)。若为一个整数，则它的平方值将作为池化核大小，比如若 pool_size=2，则池化核大小为 2x2。
- **stride** (int|list|tuple，可选)：池化层的步长。如果它是一个元组或列表，它将包含两个整数，(pool_stride_Height, pool_stride_Width)。若为一个整数，则表示 H 和 W 维度上 stride 均为该值。默认值为 None，这时会使用 kernel_size 作为 stride。
- **padding** (str|int|list|tuple，可选) 池化填充。



 ==nn.Flatten（）==

构造一个 `Flatten` 类的可调用对象。它实现将一个连续维度的 Tensor 展平成一维 Tensor。

> 就是一个能够实现快速向量化的过程



==nn.Linear（）==

构造一个全连接层，依照权重参数以及偏差进行计算。

<img src="https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230119111936428-1674135943449-3.png" alt="image-20230119111936428" style="zoom:67%;" />

下面是基本的参数：

- **in_features** (int) – 线性变换层输入单元的数目。
- **out_features** (int) – 线性变换层输出单元的数目。

==paddle.summary()==

通过 `input_size` 或 `input` 打印网络 `net` 的基础结构和参数信息。

大致的具体参数如下：

- **net** (Layer) - 网络实例，必须是 `Layer` 的子类。
- **input_size** (tuple|InputSpec|list[tuple|InputSpec，可选) - 输入张量的大小。

> 使用paddle.summary（）可以直接观察我们设置好的网络网络结构：

下面是一个观察LeNet传统结构网络的实践：

> networkz这一网络实例我们在之前已经完成设置

![image-20230119113058015](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230119113058015-1674135943449-5.png)

---

### model对象

==paddle.Model==

`Model` 对象是一个具备训练、测试、推理的神经网络。

包含训练测试推理等方法，可以用API调用，快速进行配置。下面按照一般调用顺序解释：

#### model

```python
#模型封装
model = paddle.Model(network_2)
```

> 此处是进行模型的封装，把之前搭建的网络架构封装到model对象中。

#### model.prepare

```python
#模型配置
model.prepare(paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()),
              paddle.nn.CrossEntropyLoss(),
              paddle.metric.Accuracy())
```

> 此处的prepare是model对象中的一个方法，具体作用是配置模型所需的部件，比如优化器、损失函数和评价指标。

prepare的主要参数包含下面部分：

- **optimizer** (Optimizer|None，可选) - 当训练模型的，该参数必须被设定。当评估或测试的时候，该参数可以不设定。默认值：None。
- **loss** (Loss|Callable|None，可选) - 当训练模型的，该参数必须被设定。默认值：None。
- **metrics** (Metric|list[Metric]|None，可选) - 当该参数被设定时，所有给定的评估方法会在训练和测试时被运行，并返回对应的指标。默认值：None。

> 第一个参数优化器的选择也是直接调用API即可，优化器的选择很广泛，具体查询API-optimizer文档：
>
> [paddle.optimizer-API文档-PaddlePaddle深度学习平台](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html#about-optimizer)
>
> 如上面举例代码使用的是Adam优化器，利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。

> 第二个参数loss函数的选择同样是API调用，根据loss进行对应调用，查询API-Loss文档：
>
> [paddle.nn-API文档-PaddlePaddle深度学习平台](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Overview_cn.html#loss-layers)
>
> 上述代码使用的是CrossEntropyLoss函数，交叉熵损失函数。

> 第三个参数是评估器的选择，根据需求调用API：
>
> [paddle.metric-API文档-PaddlePaddle深度学习平台](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/metric/Overview_cn.html#paddle-metric)
>
> 上述代码使用的是accuracy，计算准确率。



#### model.fit

```python
#训练模型
model.fit(train_dataset, 
          eval_dataset,  
          epochs=5,       
          batch_size=64, 
          verbose=1)      
```

fit方法主要参数含义如下：

- **train_data** (Dataset|DataLoader，可选) - 一个可迭代的数据源，推荐给定一个 `paddle paddle.io.Dataset` 或 `paddle.io.Dataloader` 的实例。默认值：None。
- **eval_data** (Dataset|DataLoader，可选) - 一个可迭代的数据源，推荐给定一个 `paddle paddle.io.Dataset` 或 `paddle.io.Dataloader` 的实例。当给定时，会在每个 `epoch` 后都会进行评估。默认值：None。
- **batch_size** (int，可选) - 训练数据或评估数据的批大小，一次获取的数据样本大小。当 `train_data` 或 `eval_data` 为 `DataLoader` 的实例时，该参数会被忽略。默认值：1。
- **epochs** (int，可选) - 训练的轮数。默认值：1。
- **eval_freq** (int，可选) - 评估的频率，多少个 `epoch` 评估一次。默认值：1。
- **log_freq** (int，可选) - 日志打印的频率，多少个 `step` 打印一次日志。默认值：10。
- **save_dir** (str|None，可选) - 保存模型的文件夹，如果不设定，将不保存模型。默认值：None。
- **save_freq** (int，可选) - 保存模型的频率，多少个 `epoch` 保存一次模型。默认值：1。
- **verbose** (int，可选) - 可视化的模型，必须为 0，1，2。当设定为 0 时，不打印日志，设定为 1 时，使用进度条的方式打印日志，设定为 2 时，一行一行地打印日志。默认值：2。

> 以上是模型训练的配置的参数含义

#### model.evaluate

```python
result = model.evaluate(eval_dataset, verbose=1)
```

进行模型评估，包括loss以及准确率等评估因素

以下是主要的参数含义：

- **eval_data** (Dataset|DataLoader) - 一个可迭代的数据源，推荐给定一个 `paddle.io.Dataset` 或 `paddle.io.Dataloader` 的实例。默认值：None。
- **batch_size** (int，可选) - 训练数据或评估数据的批大小，当 `eval_data` 为 `DataLoader` 的实例时，该参数会被忽略。默认值：1。
- **log_freq** (int，可选) - 日志打印的频率，多少个 `step` 打印一次日志。默认值：10。
- **verbose** (int，可选) - 可视化的模型，必须为 0，1，2。当设定为 0 时，不打印日志，设定为 1 时，使用进度条的方式打印日志，设定为 2 时，一行一行地打印日志。默认值：2。

#### model.predict

```python
result = model.predict(eval_dataset)
```

下面是主要的参数含义：

- **test_data** (Dataset|DataLoader) - 一个可迭代的数据源，推荐给定一个 `paddle.io.Dataset` 或 `paddle.io.Dataloader` 的实例。默认值：None。
- **batch_size** (int，可选) - 训练数据或评估数据的批大小，当 `test_data` 为 `DataLoader` 的实例时，该参数会被忽略。默认值：1。
- **num_workers** (int，可选) - 启动子进程用于读取数据的数量。当 `test_data` 为 `DataLoader` 的实例时，该参数会被忽略。默认值：True。
- **stack_outputs** (bool，可选) - 是否将输出进行堆叠。比如对于单个样本输出形状为 `[X, Y]`，`test_data` 包含 N 个样本的情况，如果 `stack_outputs` 设置为 True，那么输出的形状将会是 `[N, X, Y]`，如果 `stack_outputs` 设置为 False，那么输出的形状将会是 `[[X, Y], [X, Y], ..., [X, Y]]`。将 `stack_outputs` 设置为 False 适用于输出为 LoDTensor 的情况，如果输出不包含 LoDTensor，建议将其设置为 True。默认值：False。
- **verbose** (int，可选) - 可视化的模型，必须为 0，1，2。当设定为 0 时，不打印日志，设定为 1 时，使用进度条的方式打印日志，设定为 2 时，一行一行地打印日志。默认值：1。

#### model.save

```python
model.save('finetuning/mnist')
```

将模型的参数和训练过程中优化器的信息保存到指定的路径，以及推理所需的参数与文件。

- **path** (str) - 保存的文件名前缀。格式如 `dirname/file_prefix` 或者 `file_prefix` 。
- **training** (bool，可选) - 是否保存训练的状态，包括模型参数和优化器参数等。如果为 False，则只保存推理所需的参数与文件。默认值：True。



## 完整代码：

```python 
import paddle
import numpy as np
import matplotlib.pyplot as plt
import paddle.nn as nn

# 数据预处理
import paddle.vision.transforms as T
transform = T.Normalize(mean=[127.5], std=[127.5])
# 训练数据集
train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)
# 验证数据集
eval_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)
print('训练样本量：{}，测试样本量：{}'.format(len(train_dataset), len(eval_dataset)))

#LeNet网络结构的搭建
network_LeNet = nn.Sequential(
    nn.Conv2D(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1), 
    nn.ReLU(),
    nn.MaxPool2D(kernel_size=2, stride=2),
    nn.Conv2D(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),
    nn.ReLU(),
    nn.MaxPool2D(kernel_size=2, stride=2),
    nn.Flatten(),
    nn.Linear(in_features=400, out_features=120),  
    nn.Linear(in_features=120, out_features=84),
    nn.Linear(in_features=84, out_features=10)
)
paddle.summary(network_LeNet, (1, 1, 28, 28))#可视化模型

model = paddle.Model(network_LeNet) #模型封装

model.prepare(paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()), 
              paddle.nn.CrossEntropyLoss(), 
              paddle.metric.Accuracy())  #模型配置

model.fit(train_dataset,  
          eval_dataset,   
          epochs=5,       
          batch_size=64,  
          verbose=1)   #模型训练

result = model.evaluate(eval_dataset, verbose=1) #模型评估
print(result)

result = model.predict(eval_dataset) #推理

```

## AlexNet主体

> 对于AlexNet的理解认识：
>
> 相较于LeNet，有着更深的网络深度，基本的组合还是若干组【卷积+激活函数+池化】或者是【卷积+激活函数】，接近网络末端时，展开进入全连接层，增加了dropout，随机舍去部分神经元，这样能够减少神经元之间的相关性，避免过拟合。

```python
network_AlexNet = nn.Sequential(
    nn.Conv2D(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=5),
    nn.ReLU(),
    nn.MaxPool2D(kernel_size=2, stride=2),
    nn.Conv2D(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),
    nn.ReLU(),
    nn.MaxPool2D(kernel_size=2, stride=2),
    nn.Conv2D(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),
    nn.ReLU(),
    nn.Conv2D(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),
    nn.ReLU(),
    nn.Conv2D(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),
    nn.ReLU(),
    nn.MaxPool2D(kernel_size=2, stride=2),
    nn.Flatten(),
    nn.Linear(in_features=256, out_features=4096),
    nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(in_features=4096, out_features=4096),
    nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(in_features=4096, out_features=10)
)
```

网络结构的搭建主要还是对于paddle框架高层API的调用，API的具体含义已经在LeNet的笔记中做了详细记录，此处不再重复说明。



## 项目实现过程记录：

> 导入数据集

![image-20230119210422424](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230119210422424-1674135963802-10.png)

> ALexNet网络主体搭建

![image-20230119210556098](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230119210556098-1674135963802-12.png)

> 模型封装、参数配置以及模型训练

![image-20230119210826514](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230119210826514-1674135963802-14.png)

> 模型评估以及推理

![image-20230119211004509](https://yoga-typora-photo.oss-cn-beijing.aliyuncs.com/typora_img/image-20230119211004509-1674135963802-16.png)



## 完整的代码：

```python
import paddle
import numpy as np
import matplotlib.pyplot as plt
import paddle.nn as nn

# 数据预处理
import paddle.vision.transforms as T
transform = T.Normalize(mean=[127.5], std=[127.5])
# 训练数据集
train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)
# 验证数据集
eval_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)
print('训练样本量：{}，测试样本量：{}'.format(len(train_dataset), len(eval_dataset)))

#AlexNet网络结构的搭建
network_AlexNet = nn.Sequential(
    nn.Conv2D(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=5),
    nn.ReLU(),
    nn.MaxPool2D(kernel_size=2, stride=2),
    nn.Conv2D(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),
    nn.ReLU(),
    nn.MaxPool2D(kernel_size=2, stride=2),
    nn.Conv2D(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),
    nn.ReLU(),
    nn.Conv2D(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),
    nn.ReLU(),
    nn.Conv2D(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),
    nn.ReLU(),
    nn.MaxPool2D(kernel_size=2, stride=2),
    nn.Flatten(),
    nn.Linear(in_features=256, out_features=4096),
    nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(in_features=4096, out_features=4096),
    nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(in_features=4096, out_features=10)
)
paddle.summary(network_AlexNet, (1, 1, 28, 28))#可视化模型

model = paddle.Model(network_AlexNet) #模型封装

model.prepare(paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()), 
              paddle.nn.CrossEntropyLoss(), 
              paddle.metric.Accuracy())  #模型配置

model.fit(train_dataset,  
          eval_dataset,   
          epochs=5,       
          batch_size=64,  
          verbose=1)   #模型训练

result = model.evaluate(eval_dataset, verbose=1) #模型评估
print(result)

result = model.predict(eval_dataset) #推理
```

# 进度总结：

基本完成了年前预期的任务，手写数字识别以及吴恩达的深度学习课程都已经完成，当然对于神经网络具体的训练、评估等问题还是留有疑问的，同样对于神经网络的构造也持有疑问，卷积层和池化层等组合使用到什么程度，核的大小怎么选择？毕竟这次我只是调用了高层API完成了训练以及评估。例如训练模型的底层代码我就不太熟悉了解，希望过年期间能够把这些小疑问解决。





