## 三月18日



我在原数据集的基础上，编写了脚本随机删除了400张标签数量最多的锥桶图像，

处理后标签的数量分布如下，整体上较为均衡。



![image-20230318134600196](E:/typora/photo/image-20230318134600196-1679152004681-1.png)

进行了30轮次的训练，差不多是98，提升不显著。

以此为基础，我打算使用在线数据增强的手段，来提高数据上限：

![image-20230318204518172](E:/typora/photo/image-20230318204518172-1679152004681-3.png)

提交后，效果不理想，我认为原因一是数据均衡用的是下采样，二是数据增强方法过于繁杂

![image-20230318225319694](E:/typora/photo/image-20230318225319694-1679152004681-5.png)

看了下去年的冠军方案，我学习到了如下的几个思路：

> [第十七届全国大学生智能汽车竞赛：智慧交通组创意赛线上资格赛-冠军方案 - 飞桨AI Studio (baidu.com)](https://aistudio.baidu.com/aistudio/projectdetail/4217664)

> 1.考虑输入图像尺寸变更的性能影响
>
> 2.在`PaddleDetection/ppdet/modeling/heads/ppyoloe_head.py`中，将GIoULoss换成DIouLoss，对loss的优化，收敛速度或许会加速

打算明天尝试下进一步考虑输入图像尺寸变更的性能影响，多尺度是方法之一，而且我们的目标大多数小目标，我觉得整体输出尺寸的偏大对小目标检测或许会有不错的效果？